{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from git import Repo\n",
    "import os\n",
    "import re\n",
    "import string\n",
    "import gensim\n",
    "import ast\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify the list of repository urls to crawl\n",
    "repository_list = ['https://github.com/matplotlib/matplotlib.git',\n",
    "                    'https://github.com/scikit-learn/scikit-learn.git',\n",
    "                    'https://github.com/numpy/numpy.git',\n",
    "                    'https://github.com/scipy/scipy.git',\n",
    "                    'https://github.com/pallets/flask.git',\n",
    "                    'https://github.com/psf/requests.git',\n",
    "                    'https://github.com/scrapy/scrapy']\n",
    "\n",
    "# specify the path of the output text file\n",
    "output_file = \"python_files.txt\"\n",
    "\n",
    "# loop through all repository urls\n",
    "for url in repository_list:\n",
    "    # clone the repository to a temporary directory\n",
    "    repo_dir = os.path.join(os.getcwd(), \"temp\")\n",
    "    Repo.clone_from(url, repo_dir)\n",
    "\n",
    "    # loop through all Python files in the repository\n",
    "    for root, dirs, files in os.walk(repo_dir):\n",
    "        for file in files:\n",
    "            if file.endswith(\".py\"):\n",
    "                # get the contents of the Python file\n",
    "                file_path = os.path.join(root, file)\n",
    "                with open(file_path, \"r\", encoding='utf-8') as f:\n",
    "                    file_content = f.read()\n",
    "                # write the contents of the Python file to the output file\n",
    "                with open(output_file, \"a\", encoding='utf-8') as f:\n",
    "                    f.write(f\"Repository: {url}\\nFile: {file_path}\\n\\n{file_content}\\n\\n{'-'*50}\\n\\n\")\n",
    "\n",
    "    # delete the temporary directory\n",
    "    os.system(f\"rm -rf {repo_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lines: 1439996\n"
     ]
    }
   ],
   "source": [
    "# Count the number of lines of code in this file\n",
    "num_lines = 0\n",
    "\n",
    "with open('python_files.txt', 'r', encoding='utf-8') as file:\n",
    "    lines = file.readlines()\n",
    "    num_lines = len(lines)\n",
    "\n",
    "print(f\"Lines: {num_lines}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of tokens: 5978486\n"
     ]
    }
   ],
   "source": [
    "# Creates a function that counts the number of words in output file\n",
    "def tokenize(path):\n",
    "\n",
    "    token_list = []\n",
    "\n",
    "    # count the number of tokens in the file\n",
    "    with open(path, \"r\", encoding='utf-8') as f:\n",
    "        file_content = f.read()\n",
    "\n",
    "    tokens = re.findall(r'\\b\\w+\\b', file_content)\n",
    "    token_list.append(tokens)\n",
    "    num_tokens = len(tokens)\n",
    "    print(f\"Number of tokens: {num_tokens}\")\n",
    "\n",
    "    return token_list\n",
    "\n",
    "tokenized_list = tokenize(\"python_files.txt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 29892430)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train your Gensim Word2Vec model with the tokenized lines of code\n",
    "model = gensim.models.Word2Vec(\n",
    "    window=10,\n",
    "    min_count=2\n",
    ")\n",
    "\n",
    "model.build_vocab(tokenized_list)\n",
    "\n",
    "model.train(tokenized_list, total_examples=model.corpus_count, epochs=model.epochs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('to', 0.9962059855461121),\n",
       " ('not', 0.9961488842964172),\n",
       " ('f', 0.996028482913971),\n",
       " ('in', 0.9957643151283264),\n",
       " ('the', 0.9957113862037659),\n",
       " ('name', 0.9956578612327576),\n",
       " ('return', 0.9954971075057983),\n",
       " ('if', 0.9953508377075195),\n",
       " ('sphinx', 0.9949526190757751),\n",
       " ('this', 0.9948042035102844)]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Explored the trained model by examining the closest_words to “for”\n",
    "model.wv.most_similar('for')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('in', 0.9966590404510498),\n",
       " ('to', 0.9966531991958618),\n",
       " ('f', 0.9965929388999939),\n",
       " ('return', 0.9965319633483887),\n",
       " ('app', 0.9964976906776428),\n",
       " ('not', 0.9964142441749573),\n",
       " ('name', 0.9961705207824707),\n",
       " ('the', 0.9958152174949646),\n",
       " ('path', 0.9957109689712524),\n",
       " ('as', 0.9956626892089844)]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Explored the trained model by examining the closest_words to “if”\n",
    "model.wv.most_similar('if')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.32239005"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Examining the popular identifier names like \"math\" and \"numpy\" and the similarity between them\n",
    "model.wv.similarity('math','numpy')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "vscode": {
   "interpreter": {
    "hash": "8e006b92cf6911bb559bf685cd6f76a0f36181bfcf0c5c8daa6ec7e16acca149"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
